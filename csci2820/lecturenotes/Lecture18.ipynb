{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\mymat}[1]{\n",
    "\\left[\n",
    "\\begin{array}{rrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrrr}\n",
    "#1\n",
    "\\end{array}\n",
    "\\right]\n",
    "}\n",
    "\\newcommand{\\myaug}[1]{\n",
    "\\left[\n",
    "\\begin{array}{rrr|r}\n",
    "#1\n",
    "\\end{array}\n",
    "\\right]\n",
    "}\n",
    "\\newcommand{\\myp}[1]{\\left( #1 \\right)}\n",
    "\\newcommand{\\myb}[1]{\\left[ #1 \\right]}\n",
    "\\newcommand{\\myv}[1]{\\left< #1 \\right>}\n",
    "\\newcommand{\\mys}[1]{\\left\\{ #1 \\right\\}}\n",
    "\\newcommand{\\myab}[1]{\\left| #1 \\right|}\n",
    "\\newcommand{\\bx}{{\\bf x}}\n",
    "\\newcommand{\\by}{{\\bf y}}\n",
    "\\newcommand{\\bu}{{\\bf u}}\n",
    "\\newcommand{\\bv}{{\\bf v}}\n",
    "\\newcommand{\\bw}{{\\bf w}}\n",
    "\\newcommand{\\be}{{\\bf e}}\n",
    "\\newcommand{\\R}[1]{\\mathbb{R}^{ #1 }}\n",
    "\\newcommand{\\hs}{\\hspace{1mm}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Orthonormal Bases, Gram-Schmidt, and QR\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "We've now spent a good deal of time talking about projections, and what they can do for us.  In particular, projections are at the heart of solving the **least-squares problem** which is used for data fitting.  It turns out that projections because super easy if you have an **orthogonal basis** for the subspace you're projecting on to. \n",
    "\n",
    "<br>\n",
    "\n",
    "Suppose ${\\bf a}_1, {\\bf a}_2,{\\bf a}_3$ form a basis for some subspace $\\mathcal{S}$.  If some vector ${\\bf b}$ in $\\mathcal{S}$ is given by ${\\bf b} = 1{\\bf a}_1 + 2{\\bf a}_2 - 3{\\bf a}_3$ we say that $(1,2,-3)$ are the **coordinates** of ${\\bf b}$ with respect to the basis. \n",
    "\n",
    "<br>\n",
    "\n",
    "OK, so given a vector ${\\bf b}$ in $\\mathcal{S}$ and the basis vectors, how do we find the coordinates of ${\\bf b}$?  \n",
    "\n",
    "<bf>\n",
    "\n",
    "One way we could do this is to stack the basis vectors in a matrix, $A = \\mymat{{\\bf a}_1 & {\\bf a}_2 & {\\bf a}_3}$ and solve the linear system \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf b} = A{\\bf x} = \\mymat{{\\bf a}_1 & {\\bf a}_2 & {\\bf a}_3}\\mymat{x_1 \\\\ x_2 \\\\ x_3}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "OK, so sometimes this is easy, but sometimes it's hard.  It turns out that things get way easier if your basis vectors are orthogonal.  Things get even *nicer* if the basis vectors are orthogonal and have unit length. \n",
    "\n",
    "<br>\n",
    "\n",
    "Consider the way we generally think of vectors in $\\R{3}$.  The vector $\\myb{1, 2, -3}^T$ has coordinates $(1,2,-3)$ with respect to the standard basis vectors ${\\bf e}_1$, ${\\bf e}_2$, and ${\\bf e}_3$. The standard basis vectors are orthogonal and have unit length! \n",
    "\n",
    "<br>\n",
    "\n",
    "But there can be other bases with this same property.  Suppose that ${\\bf q}_1, {\\bf q}_2,$ and ${\\bf q}_3$ are a basis for some subspace $\\mathcal{S}$ that satisfy \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf q}_i^T{\\bf q}_j = 0 \\quad \\textrm{for } i \\neq j \\quad \\textrm{and also} \\quad \\|{\\bf q}_j\\| = 1 \\quad \\textrm{for all } j\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Then we say that the ${\\bf q}$'s form an **orthonormal** basis for $\\mathcal{S}$. \n",
    "\n",
    "<br>\n",
    "\n",
    "OK, so how do we find $x_1$, $x_2$, and $x_3$ such that ${\\bf b} = x_1{\\bf q}_1 + x_2 {\\bf q}_2 + x_3 {\\bf q}_3$? \n",
    "\n",
    "<br>\n",
    "\n",
    "Notice that if we take the dot product of ${\\bf b}$ with ${\\bf q}_1$ we get \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf q}_1^T {\\bf b} = x_1 {\\bf q}_1^T{\\bf q}_1 + x_2 {\\bf q}_1^T{\\bf q}_2 + x_3 {\\bf q}_1^T{\\bf q}_3 = x_1\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "where the last equality follows from the fact that the dot product of ${\\bf q}_1$ with ${\\bf q}_2$ and ${\\bf q}_3$ are both zero, because they're orothogonal.  Also, the dot product of ${\\bf q}_1$ with itself is zero. \n",
    "\n",
    "<br>\n",
    "\n",
    "Similarly, we have \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf q}_2^T {\\bf b} = x_1 {\\bf q}_2^T{\\bf q}_1 + x_2 {\\bf q}_2^T{\\bf q}_2 + x_3 {\\bf q}_2^T{\\bf q}_3 = x_2\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf q}_3^T {\\bf b} = x_1 {\\bf q}_3^T{\\bf q}_1 + x_2 {\\bf q}_3^T{\\bf q}_2 + x_3 {\\bf q}_1^T{\\bf q}_3 = x_3\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "So, if we have an orthonormal basis, finding the coordinates of ${\\bf b}$ in that basis are as simple as taking the dot product of the basis vectors with ${\\bf b}$.  That's **way easier** than solving a linear system. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Example 1**: Let ${\\bf q}_1 = \\mymat{1/3 \\\\ 2/3 \\\\ 2/3}$, ${\\bf q}_2 = \\mymat{-2/3 \\\\ -1/3 \\\\ 2/3}$, and ${\\bf q}_3 = \\mymat{2/3 \\\\ -2/3 \\\\ 1/3}$. Find the coords of ${\\bf b} = \\mymat{1 \\\\ 0 \\\\ 0}$ in this basis. \n",
    "\n",
    "<br>\n",
    "\n",
    "We have \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "x_1 = {\\bf q}_1^T{\\bf b} = 1/3, \\quad\n",
    "x_2 = {\\bf q}_2^T{\\bf b} = -2/3, \\quad\n",
    "x_3 = {\\bf q}_3^T{\\bf b} = 2/3 \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "So \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\mymat{1 \\\\ 0 \\\\ 0} = \\frac{1}{3}{\\bf q}_1 - \\frac{2}{3}{\\bf q}_2 + \\frac{2}{3}{\\bf q}_3\n",
    "= \\mymat{1/9 \\\\ 2/9 \\\\ 2/9} + \\mymat{4/9 \\\\ 2/9 \\\\ -4/9} + \\mymat{4/9 \\\\ -4/9 \\\\ 2/9} = \n",
    "\\mymat{1 \\\\ 0 \\\\ 0} \\quad \\checkmark\n",
    "$$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice things happen when we put orthonormal vectors into a matrix.  Consider $Q = \\mymat{{\\bf q}_1 & {\\bf q}_2 & {\\bf q}_3}$ where the ${\\bf q}'s$ are length-m vectors. Notice that \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "Q^TQ = \n",
    "\\mymat{\n",
    "{\\bf q}_1^T{\\bf q}_1 & {\\bf q}_1^T{\\bf q}_2 & {\\bf q}_1^T{\\bf q}_3 \\\\\n",
    "{\\bf q}_2^T{\\bf q}_1 & {\\bf q}_2^T{\\bf q}_2 & {\\bf q}_2^T{\\bf q}_3 \\\\ \n",
    "{\\bf q}_3^T{\\bf q}_1 & {\\bf q}_3^T{\\bf q}_2 & {\\bf q}_3^T{\\bf q}_3 \\\\ \n",
    "} = I \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example 2**: Let $Q = \\mymat{1/\\sqrt{2} & 1/\\sqrt{3} \\\\ 0 & 1/\\sqrt{3} \\\\ 1/\\sqrt{2} & -1/\\sqrt{3}}$.  Then \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "Q^TQ = \n",
    "\\mymat{\n",
    "1/\\sqrt{2} & 0 &  1/\\sqrt{2} \\\\ \n",
    "1/\\sqrt{3} & 1/\\sqrt{3}& -1/\\sqrt{3}\n",
    "}\n",
    "\\mymat{\n",
    "1/\\sqrt{2} & 1/\\sqrt{3} \\\\ \n",
    "0 & 1/\\sqrt{3} \\\\ \n",
    "1/\\sqrt{2} & -1/\\sqrt{3}\n",
    "}\n",
    "= \n",
    "\\mymat{\n",
    "1/2 + 1/2 & 1/\\sqrt{6}-1/\\sqrt{6} \\\\\n",
    "1/\\sqrt{6} - 1/\\sqrt{6} & 1/3 + 1/3 + 1/3\n",
    "}\n",
    "= I \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "If the matrix $Q$ with orthonormal columns is a square matrix then $QQ^T = I$ as well.  But if $Q$ is not square then $QQ^T \\neq I$.  \n",
    "\n",
    "<br>\n",
    "\n",
    "If $Q$ is square and $Q^TQ = QQ^T = I$ then we call $Q$ an **orthogonal matrix**. \n",
    "\n",
    "<br>\n",
    "\n",
    "Notice that a nice property of orthogonal matrices is that $Q^T = Q^{-1}$!\n",
    "\n",
    "<br>\n",
    "\n",
    "Orthogonal matrices exhibit nice properties when they act on vectors.  In particular, multiplcation of a vector by an orthogonal matrix does not change the length of the vector.  Furthermore, if you apply an orthogonal matrix to two vectors, it does not change the angle between the two vectors. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Proof**:  If $Q$ is orthogonal then $\\|Q\\bx\\| = \\|\\bx\\|$. \n",
    "\n",
    "<br>\n",
    "\n",
    "We'll show the equivalent fact that $\\|Q\\bx\\|^2 = \\|\\bx\\|^2$. \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\|Q\\bx\\|^2 = \\myp{Q\\bx}^T\\myp{Q\\bx} = \\bx^TQ^TQ\\bx = \\bx^TI\\bx = \\bx^T\\bx = \\|\\bx\\|^2\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Proof**: If $Q$ is orthogonal then $Q\\bx \\cdot Q\\by = \\bx \\cdot \\by$. \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "(Q\\bx) \\cdot (Q\\by) = (Q\\bx)^T(Q\\by) = \\bx^TQ^TQ\\by = \\bx^TI\\by = \\bx^T\\by = \\bx \\cdot \\by\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Having an orthonormal basis for a subspace makes projecting onto that subspace extraordinarily easy.  Suppose that ${\\bf q}_1$, ${\\bf q}_2$, ${\\bf q}_3$ is a basis for $\\mathcal{S}$ and let $Q = \\mymat{{\\bf q}_1 & {\\bf q}_2 & {\\bf q}_3}$. Then the projection of ${\\bf b}$ onto $\\mathcal{S}$ is given by ${\\bf p} = Q\\hat{\\bx}$ where $\\hat{x}$ solves the normal equations $Q^TQ\\bx = Q^T{\\bf b}$.  But $Q^TQ = I$ so we have immediately $\\hat{\\bx} = Q^T{\\bf b}$. Plugging this into the projection equation we have ${\\bf p} + QQ^T{\\bf b}$, which means that the usually complicated to compute projection matrix is given by $P = QQ^T$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so an orthonormal basis for a subspace makes projects easier.  But, given any old basis for a subspace ${\\bf a}_1$, {\\bf a}_2, \\ldots, {\\bf a}_n$, can we come up with an orthonormal basis for that same subspace?  \n",
    "\n",
    "The answer is YES, and it's done using an algorithm called the **Gram-Schmidt** process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's starting with an easy case where we have two linearly independent vectors ${\\bf w}_1$ and ${\\bf w}_2$ and we want to find orthonormal vectors ${\\bf q}_1$ and ${\\bf q}_2$ such that $\\textrm{span}\\left\\{{\\bf q}_1, {\\bf q}_2\\right\\} = \\textrm{span}\\left\\{{\\bf w}_1, {\\bf w}_2\\right\\}$. \n",
    "\n",
    "<br>\n",
    "\n",
    "We're going to start by finding vectors ${\\bf v}_1$ and ${\\bf v}_2$ which are orthogonal and span the same space as ${\\bf w}_1$ and ${\\bf w}_2$.  Then we'll scale them to have unit length.  \n",
    "\n",
    "<br>\n",
    "\n",
    "The first step is to simply set ${\\bf v}_1 = {\\bf w}_1$. \n",
    "\n",
    "<br>\n",
    "\n",
    "Next we define ${\\bf v}_2$ as follows\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf v}_2 = {\\bf w}_2 - r{\\bf v}_1 \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "where $r$ is a yet-to-be determined constant.  Notice that necessarly the ${\\bf v}$'s span the same space as the ${\\bf w}$'s since the ${\\bf v}'s$ are simple linear combinations of the ${\\bf w}$'s.  To make it so that ${\\bf w}_2$ is orthogonal to ${\\bf w}_1$ we simply choose $r$ t make it so.  We do this by dotting ${\\bf w}_1$ and ${\\bf w}_2$ together and choosing $r$ so that the result is zero. \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf v}_2^T{\\bf v}_1 = ({\\bf w}_2 - r{\\bf v}_1)^T {\\bf v}_1 = 0\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Distributing the dot product, we have\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf w}_2^T{\\bf v}_1 - r{\\bf v}_1^T{\\bf v}_1 = 0 \\quad \\Rightarrow \\quad {\\bf w}_2^T{\\bf v}_1 = r{\\bf v}_1^T{\\bf v}_1 \\quad \\Rightarrow \\quad r = \\frac{{\\bf w}_2^T{\\bf v}_1}{{\\bf v}_1^T{\\bf v}_1}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Then ${\\bf v_2} = {\\bf w}_2 - \\dfrac{{\\bf w}_2^T{\\bf v}_1}{{\\bf v}_1^T{\\bf v}_1}{\\bf v}_1$\n",
    "\n",
    "<br>\n",
    "\n",
    "The last step is to normalize the ${\\bf v}$'s: \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf q}_1 = \\dfrac{{\\bf v}_1}{\\|{\\bf v}_1\\|}\n",
    "\\quad \\textrm{and} \\quad\n",
    "{\\bf q}_2 = \\dfrac{{\\bf v}_2}{\\|{\\bf v}_2\\|}\n",
    "$$\n",
    "\n",
    "<bf>\n",
    "\n",
    "**Example 2**: Let ${\\bf w}_1 = \\mymat{1 \\\\ 1 \\\\ 1}$ and ${\\bf w}_2 = \\mymat{0 \\\\ 1 \\\\ 2}$. \n",
    "\n",
    "<br>\n",
    "\n",
    "First we set ${\\bf v}_1 = {\\bf w}_1 = \\mymat{1 \\\\ 1 \\\\ 1}$. Next we compute $r = \\dfrac{{\\bf w}_2^T{\\bf v}_1}{{\\bf v}_1^T{\\bf v}_1} = \\dfrac{3}{3}$.  Then we form \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf v}_2 = {\\bf w}_2 - r{\\bf v}_1 = \\mymat{0 \\\\ 1 \\\\ 2} - \\frac{3}{3}\\mymat{1 \\\\ 1 \\\\ 1} = \\mymat{-1 \\\\ 0 \\\\ 1}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Normalizing, we have \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf q}_1 = \\frac{1}{\\sqrt{3}}\\mymat{1 \\\\ 1 \\\\ 1} \\quad \\textrm{and} \\quad \n",
    "{\\bf q}_2 = \\frac{1}{\\sqrt{2}}\\mymat{-1 \\\\ 0 \\\\ 1} \\quad \\textrm{and} \\quad \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Now, what if we add a third vector into the mix? \n",
    "\n",
    "<br>\n",
    "\n",
    "**Example 3**: Find an orthonormal basis for the space spanned by ${\\bf w}_1 = \\mymat{1 \\\\ 1 \\\\ 1}$, ${\\bf w}_2 = \\mymat{0 \\\\ 1 \\\\ 2}$, and ${\\bf w}_3 = \\mymat{0 \\\\ 2 \\\\ 1}$.\n",
    "\n",
    "<br>\n",
    "\n",
    "The good news is that the word we did in Example 2 is still good.  We already have vectors ${\\bf v}_1$ and ${\\bf v}_2$ that are orthogonal and in the desired space.  Next we need to choose ${\\bf v}_3$ that is orthogonal to ${\\bf v}_1$ and ${\\bf v}_2$ and is in the span of the ${\\bf w}$'s.  We do this by writing ${\\bf v}_2$ as a linear combination of ${\\bf v}_1$ and ${\\bf v}_2$: \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf v}_3 = {\\bf w}_3 - r_1{\\bf v}_1 - r_2{\\bf v}_2\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "The coefficients $r_1$ and $r_2$ will be chosen to enforce the orthogonality.  We have \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "0 = {\\bf v}_3^T{\\bf v_1} = ({\\bf w}_3 - r_1{\\bf v}_1 - r_2{\\bf v}_2)^T{\\bf v}_1 \n",
    "\\quad \\Rightarrow \\quad\n",
    "0 = {\\bf w}_3^T{\\bf v}_1- r_1 {\\bf v}_1^T{\\bf v}_1\n",
    "\\quad \\Rightarrow \\quad \n",
    "r_1 = \\frac{{\\bf w}_3^T{\\bf v}_1}{{\\bf v}_1^T{\\bf v}_1}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "0 = {\\bf v}_3^T{\\bf v_2} = ({\\bf w}_3 - r_1{\\bf v}_1 - r_2{\\bf v}_2)^T{\\bf v}_2 \n",
    "\\quad \\Rightarrow \\quad\n",
    "0 = {\\bf w}_3^T{\\bf v}_2- r_2 {\\bf v}_2^T{\\bf v}_2\n",
    "\\quad \\Rightarrow \\quad \n",
    "r_2 = \\frac{{\\bf w}_3^T{\\bf v}_2}{{\\bf v}_2^T{\\bf v}_2}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "For this example, we have \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "r_1 = \\frac{3}{3} = 1 \\quad \\textrm{and} \\quad r_2 = \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Then \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "{\\bf v}_3 = {\\bf w}_3 - {\\bf v}_1 - \\frac{1}{2}{\\bf v}_2 = \n",
    "\\mymat{0 \\\\ 2 \\\\ 1} - \n",
    "\\mymat{1 \\\\ 1 \\\\ 1} - \n",
    "\\frac{1}{2}\\mymat{-1 \\\\ 0 \\\\ -1} = \\mymat{-1/2 \\\\ 1 \\\\ -1/2}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Normalizing then gives ${\\bf q}_3 = \\frac{1}{\\sqrt{6}}\\mymat{-1 \\\\ 2 \\\\ -1}$.\n",
    "\n",
    "<br>\n",
    "\n",
    "It turns out that the Gram-Schmidt process gives us another way to factor a matrix.  We can write $A = QR$ where $Q$ has orthonormal columns and $R$ is upper triangular.  \n",
    "\n",
    "<br>\n",
    "\n",
    "**Example 4**: Let $A = \\mymat{1 & 0 \\\\ 1 & 1 \\\\ 1 & 2}$.  We found in Example 2 that an orthonormal basis for the colum space of $A$ is given by \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "Q = \n",
    "\\mymat{\n",
    "1\\sqrt{3} & -1/\\sqrt{2} \\\\\n",
    "1\\sqrt{3} & 0 \\\\\n",
    "1\\sqrt{3} & 1/\\sqrt{2} \\\\\n",
    "}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "To get the $R$ in the QR factorization we note that since $Q$ has orthonormal columns\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "A = QR \\quad \\Rightarrow \\quad Q^TA = Q^TQR \\quad \\Rightarrow \\quad Q^TA = R \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Thus we can find $R$ simply by multiplying $A$ on the left by $Q^T$.  For this example, we have \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "R = Q^TA = \n",
    "\\mymat{\n",
    "1\\sqrt{3} & 1/\\sqrt{3} & 1/\\sqrt{3}\\\\\n",
    "-1\\sqrt{2} & 0 & 1/\\sqrt{2} \\\\\n",
    "}\n",
    "\\mymat{\n",
    "1 & 0 \\\\ \n",
    "1 & 1 \\\\ \n",
    "1 & 2}\n",
    "= \n",
    "\\mymat{\n",
    "\\sqrt{3} & \\sqrt{3} \\\\\n",
    "0 & \\sqrt{2}\n",
    "}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Thus, we can write \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\mymat{\n",
    "1 & 0 \\\\ \n",
    "1 & 1 \\\\ \n",
    "1 & 2}\n",
    "= \n",
    "\\mymat{\n",
    "1\\sqrt{3} & -1/\\sqrt{2} \\\\\n",
    "1\\sqrt{3} & 0 \\\\\n",
    "1\\sqrt{3} & 1/\\sqrt{2} \\\\\n",
    "}\n",
    "\\mymat{\n",
    "\\sqrt{3} & \\sqrt{3} \\\\\n",
    "0 & \\sqrt{2}\n",
    "}\n",
    "= QR \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "**Example 5**:  For the vectors in Example 3, we have \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\mymat{\n",
    "1 & 0 & 0  \\\\ \n",
    "1 & 1 & 2 \\\\ \n",
    "1 & 2 & 1 }\n",
    "= \n",
    "\\mymat{\n",
    "1\\sqrt{3} & -1/\\sqrt{2} & -1/\\sqrt{6}\\\\\n",
    "1\\sqrt{3} & 0  & 2/\\sqrt{6}\\\\\n",
    "1\\sqrt{3} & 1/\\sqrt{2} & -1/\\sqrt{6}\\\\\n",
    "}\n",
    "\\mymat{\n",
    "\\sqrt{3} & \\sqrt{3} & \\sqrt{3}\\\\\n",
    "0 & \\sqrt{2} & 1/\\sqrt{2} \\\\\n",
    "0 & 0 & 3/\\sqrt{6}\n",
    "}\n",
    "= QR \n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "If $A$ is a square nonsingular matrix, then the $QR$ factorization gives us another slick way to solve $A\\bx = {\\bf b}$.  We have \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "A\\bx = {\\bf b} \\quad \\Rightarrow \\quad QR\\bx = {\\bf b} \\quad \\Rightarrow \\quad Q^TQR\\bx = Q^T{\\bf b} \\quad \\Rightarrow \\quad R\\bx = Q^T{\\bf b} \\quad \\Rightarrow \\quad \\bx = R^{-1}Q^T{\\bf b}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "Thus $A\\bx = {\\bf b}$ can be solved by multiplying ${\\bf b}$ by $Q^T$ and then using back substitution to solve $R\\bx = Q^T{\\bf b}$. \n",
    "\n",
    "<br>\n",
    "\n",
    "**Example 6**: Use the QR factorization of $A$ for the matrix in Example 5 to solve $A\\bx = \\mymat{1 \\\\ 4 \\\\ 4}$. \n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "Q^T{\\bf b} = \\mymat{3\\sqrt{3} \\\\ 3/\\sqrt{2} \\\\ 3/\\sqrt{6}}\n",
    "$$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left[\n",
    "\\begin{array}{rrr|r}\n",
    "\\sqrt{3} & \\sqrt{3} & \\sqrt{3} & 3\\sqrt{3}\\\\\n",
    "0 & \\sqrt{2} & 1/\\sqrt{2}& 3/\\sqrt{2} \\\\\n",
    "0 & 0 & 3/\\sqrt{6} & 3/\\sqrt{6}\n",
    "\\end{array}\n",
    "\\right]\n",
    "\\quad \\Rightarrow \\quad\n",
    "\\begin{array}{lcl}\n",
    "x_1 = (3\\sqrt{3} - \\sqrt{3} - \\sqrt{3})/\\sqrt{3} = 1\\\\\n",
    "x_2 = (3/\\sqrt{2} - 1/\\sqrt{2}(1))/\\sqrt{2} = 1 \\\\\n",
    "x_3 = 1\n",
    "\\end{array}\n",
    "\\quad \\Rightarrow \\quad\n",
    "\\bx = \\mymat{1 \\\\ 1 \\\\ 1}\n",
    "$$\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.11",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
